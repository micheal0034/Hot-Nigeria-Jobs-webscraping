{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraper(url):\n",
    "    print('Running Engine')\n",
    "    #url = input('Please Enter the url')\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    print(f'This is the Page Title \\n{soup.title.text}')\n",
    "    \n",
    "    link = [str(i).split()[1].split('\"')[1] for i in soup.select('h1')] # creating the Link list\n",
    "    print('Link Collection Successful 100%')\n",
    "    title = [i.text for i in soup.select('h1')]\n",
    "    print('Title Collection Successful 100%')\n",
    "    \n",
    "    #Creating a dataframe of our dataset which contains title and link\n",
    "    data = pd.DataFrame(data = {'Title':title, 'Link':link}).drop_duplicates().reset_index().drop('index',axis = 1)\n",
    "    #Creating our Location\n",
    "    data['Location'] = location(data) \n",
    "    data['Location'] = update_lc(data)\n",
    "    data = data[data.Location != 'No Location'].reset_index().drop('index', axis = 1) \n",
    "    \n",
    "    \n",
    "    data['Year'] = year_update(data)[0] #Year column\n",
    "    data['Year'] = year_clean(data)\n",
    "    #data['Content'] = year_update(data)[1] #Content column\n",
    "    print('Year Collection Successful 100%')\n",
    "    #data = content(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def years(base):\n",
    "    work = []\n",
    "    year = []\n",
    "    content = []\n",
    "    if len(base) > 1:\n",
    "        for i in base:\n",
    "            if 'work' in str(base).lower() or 'experience' in str(base).lower() or 'minimum' in str(base).lower():\n",
    "                work.append(i)\n",
    "                content.append(i)\n",
    "            else:\n",
    "                #print(f'{base}')\n",
    "                work.append('No Experience 0 years')\n",
    "                content.append(base[0])\n",
    "        \n",
    "    else:\n",
    "        if 'work' in str(base).lower() or 'experience' in str(base).lower() or 'minimum' in str(base).lower():\n",
    "            work.append(base[0])\n",
    "            content.append(base)\n",
    "        else:\n",
    "            #print(f'{base}')\n",
    "            work.append('No Experience 0 years')\n",
    "            content.append(base)\n",
    "        \n",
    "    for i in work[0]:\n",
    "        for j in i :\n",
    "            if str(j) in'0123456789':\n",
    "                year.append(j)\n",
    "    return year, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_update(data):\n",
    "    year = []\n",
    "    content = []\n",
    "    for index, i in enumerate(data['Link']):\n",
    "        pagex = requests.get(i)\n",
    "        soupx = BeautifulSoup(pagex.content, 'html.parser')\n",
    "        x = [i for i in soupx.find_all('li') if 'year' in str(i)]\n",
    "        #print(index)\n",
    "        year.append(years(x)[0])\n",
    "        content.append(years(x)[1])\n",
    "    return year, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_clean(data):\n",
    "    dura = []\n",
    "    for i in data.Year:\n",
    "        if len(i) > 1:\n",
    "            if int(i[1]) == 0:\n",
    "                dura.append(str(i[0])+str(i[1]))\n",
    "            else:\n",
    "                dura.append(str(i[0]) +\"-\"+str(i[1]))\n",
    "        else:\n",
    "            if i != []:\n",
    "                dura.append(i[0])\n",
    "            else:\n",
    "                dura.append(0)\n",
    "    return dura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content(data):\n",
    "    edu = []\n",
    "    for val in data['Content']:\n",
    "        for i in val:\n",
    "            for j in i:\n",
    "                edu.append(j)\n",
    "    me = []\n",
    "    for val in edu[:len(data.Content)]:\n",
    "        if '<li>' in str(val):\n",
    "                me.append(str(val).split('>')[1].split('<')[0])\n",
    "        else:\n",
    "            me.append(val)\n",
    "    data['Content'] = me\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(data):\n",
    "    locat = []\n",
    "    for index, url in enumerate(data['Link']):\n",
    "        pagey = requests.get(url)\n",
    "        soupy = BeautifulSoup(pagey.content, 'html.parser')\n",
    "        loc = [i for i in soupy.find_all('p') if 'location' in str(i).lower()]\n",
    "        if loc != []:\n",
    "            mee = [i for i in BeautifulSoup(str(loc[0])).get_text().split('\\n') if 'location' in i.lower()][0].split('\\r')[0].split(':')[-1]\n",
    "            locat.append(mee)\n",
    "        else:\n",
    "            locat.append('No Location')\n",
    "    return locat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lc(data):\n",
    "    lc = []\n",
    "    for val in data['Location']:\n",
    "        if 'abuja' in val.lower():\n",
    "            lc.append('Abuja')\n",
    "        elif 'lagos' in val.lower():\n",
    "            lc.append('Lagos')\n",
    "        else:\n",
    "            lc.append('No Location')\n",
    "    return lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = web_scraper(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number:2\n",
      "Running Engine\n",
      "This is the Page Title \n",
      "Nigeria 350 Jobs, 350 Job Vacancies in Nigeria - 350 Jobs in Nigeria | Hot Nigerian Jobs\n",
      "Link Collection Successful 100%\n",
      "Title Collection Successful 100%\n",
      "Year Collection Successful 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% of Data Loaded\n",
      "Running Engine\n",
      "This is the Page Title \n",
      "350 Jobs in Nigeria - Page 1 | Hot Nigerian Jobs\n",
      "Link Collection Successful 100%\n",
      "Title Collection Successful 100%\n",
      "Year Collection Successful 100%\n",
      "100.0% of Data Loaded\n"
     ]
    }
   ],
   "source": [
    "data_saver_name =[]\n",
    "num = int(input('Enter the number:'))\n",
    "\n",
    "col = ['Title', 'Link', 'Year', 'Location']\n",
    "new_df = pd.DataFrame(columns=col)\n",
    "\n",
    "for i in range(num):\n",
    "    url = f'https://www.hotnigerianjobs.com/role/350/{i}/'\n",
    "    load = 'data_' + str(i)\n",
    "    data_saver_name.append(load) \n",
    "    load = web_scraper(url)\n",
    "    new_df = pd.concat([new_df, load]).reset_index(drop=True)\n",
    "    print(f'{100*((i+1)/num)}% of Data Loaded')\n",
    "new_df = new_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(dataframe):\n",
    "    name = input(\"Enter the name you want to save your file with: \")\n",
    "    dataframe.to_csv(f'{name}.csv', index=False)\n",
    "    print('Dataset has been saved to present working directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name you want to save your file withemmanuel\n",
      "Dataset has been saved to present working directory\n"
     ]
    }
   ],
   "source": [
    "data_saver(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(data):\n",
    "    desc = []\n",
    "    for index, url in enumerate(data['Link']):\n",
    "        yy = []\n",
    "        cv = []\n",
    "        page = requests.get(url).text\n",
    "        soup = BeautifulSoup(page, features=\"lxml\")\n",
    "        des = soup.find(\"div\", {\"class\":\"mycase4\"})\n",
    "\n",
    "        for i in des.find_all('ul'):\n",
    "            yy.append(str(i).replace('<li>', '** ').replace('</li>', '').replace('</ul>', '').replace('<ul>', ''))\n",
    "\n",
    "        for i in des.find_all('p'):\n",
    "            cv.append(str(i).replace('<p>', '** ').replace('</p>', '').replace('</strong>', '').replace('<strong>', '').replace('<br/>', ' '))\n",
    "        yy.append(cv[0])\n",
    "        \n",
    "        desc.append(yy[0])\n",
    "        print(index)\n",
    "        \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = x.iloc[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "cc = description(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dataframe['Job Information'] = cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Content</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Admin and Finance Assistant at Mangrove and Pa...</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323731...</td>\n",
       "      <td>0</td>\n",
       "      <td>2 - 6 years experience.</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>\\n** Have you seen anyone defecating in the op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Accountant at Russell International School</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323729...</td>\n",
       "      <td>2-6</td>\n",
       "      <td>Minimum 5 years experience</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** Preparing accounts and tax returns\\n** Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Project Accountants at Klinserv</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323721...</td>\n",
       "      <td>5</td>\n",
       "      <td>1 - 3 years Experience.</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** BSc qualification in relevant discipline\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Accounting Officers at Chartwell Securities Li...</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323602...</td>\n",
       "      <td>0-1</td>\n",
       "      <td>Candidates should possess Degree, HND, Master ...</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** Maintaining financial records.\\n** Handli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Account Officer at Ultimus Holdings</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323595...</td>\n",
       "      <td>3-5</td>\n",
       "      <td>Experience: 3-5 years work experience</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** Monitor and control of the warehouses sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Accounting Intern at Ifgreen Industries &amp; Inve...</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323593...</td>\n",
       "      <td>0</td>\n",
       "      <td>Experience Length: No Experience / Less than 1...</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** We are looking for a driven Accounting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NYSC Internship Recruitment at Ifgreen Industr...</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323591...</td>\n",
       "      <td>1</td>\n",
       "      <td>Develop and manage annual and multi-year budge...</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** Are you an NYSC intern looking for a plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Finance / Accounts Manager at SD Human Resourc...</td>\n",
       "      <td>https://www.hotnigerianjobs.com/hotjobs/323573...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assist in preparing year-end books for audit</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>\\n** Develop and manage annual and multi-year ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Admin and Finance Assistant at Mangrove and Pa...   \n",
       "1         Accountant at Russell International School   \n",
       "2                    Project Accountants at Klinserv   \n",
       "3  Accounting Officers at Chartwell Securities Li...   \n",
       "4                Account Officer at Ultimus Holdings   \n",
       "5  Accounting Intern at Ifgreen Industries & Inve...   \n",
       "6  NYSC Internship Recruitment at Ifgreen Industr...   \n",
       "7  Finance / Accounts Manager at SD Human Resourc...   \n",
       "\n",
       "                                                Link Year  \\\n",
       "0  https://www.hotnigerianjobs.com/hotjobs/323731...    0   \n",
       "1  https://www.hotnigerianjobs.com/hotjobs/323729...  2-6   \n",
       "2  https://www.hotnigerianjobs.com/hotjobs/323721...    5   \n",
       "3  https://www.hotnigerianjobs.com/hotjobs/323602...  0-1   \n",
       "4  https://www.hotnigerianjobs.com/hotjobs/323595...  3-5   \n",
       "5  https://www.hotnigerianjobs.com/hotjobs/323593...    0   \n",
       "6  https://www.hotnigerianjobs.com/hotjobs/323591...    1   \n",
       "7  https://www.hotnigerianjobs.com/hotjobs/323573...    0   \n",
       "\n",
       "                                             Content Location  \\\n",
       "0                            2 - 6 years experience.    Abuja   \n",
       "1                       Minimum 5 years experience      Lagos   \n",
       "2                            1 - 3 years Experience.    Lagos   \n",
       "3  Candidates should possess Degree, HND, Master ...    Lagos   \n",
       "4              Experience: 3-5 years work experience    Lagos   \n",
       "5  Experience Length: No Experience / Less than 1...    Lagos   \n",
       "6  Develop and manage annual and multi-year budge...    Lagos   \n",
       "7       Assist in preparing year-end books for audit    Lagos   \n",
       "\n",
       "                                     Job Information  \n",
       "0  \\n** Have you seen anyone defecating in the op...  \n",
       "1  \\n** Preparing accounts and tax returns\\n** Ad...  \n",
       "2  \\n** BSc qualification in relevant discipline\\...  \n",
       "3  \\n** Maintaining financial records.\\n** Handli...  \n",
       "4  \\n** Monitor and control of the warehouses sal...  \n",
       "5  \\n** We are looking for a driven Accounting In...  \n",
       "6  \\n** Are you an NYSC intern looking for a plac...  \n",
       "7  \\n** Develop and manage annual and multi-year ...  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
